{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"ACCuu5P8p7oC3\"\n",
    "\n",
    "from requests import Request, Session\n",
    "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
    "import json\n",
    "\n",
    "\n",
    "addresses = {\n",
    "#             \"kcs\":\"0xf34960d9d60be18cc1d5afc1a6f012a723a28811\",\n",
    "#             \"id\":\"0xebd9d99a3982d547c5bb4db7e3b1f9f14b67eb83\",\n",
    "#             \"zcn\":\"0xb9ef770b6a5e12e45983c5d80545258aa38f3b78\",\n",
    "#             \"rfuel\":\"0xaf9f549774ecedbd0966c52f250acc548d3f36e5\",\n",
    "#             \"celr\":\"0x4f9254c83eb525f9fcf346490bbb3ed28a81c667\",\n",
    "#             \"rsr\":\"0x8762db106b2c2a0bccb3a80d1ed41273552616e8\",\n",
    "#             \"orn\":\"0x0258f474786ddfd37abce6df6bbb1dd5dfc4434a\",\n",
    "# #             \"ankr\": \"0x8290333cef9e6d528dd5618fb97a76f268f3edd4\",\n",
    "#             \"ogn\":\"0x8207c1ffc5b6804f6024322ccf34f29c3541ae26\",\n",
    "#             \"matic\":\"0x7d1afa7b718fb893db30a3abc0cfc608aacfebb0\",\n",
    "#             \"omg\":\"0xd26114cd6ee289accf82350c8d8487fedb8a0c07\",\n",
    "#             \"uos\": \"0xd13c7342e1ef687c5ad21b27c2b65d772cab5c8c\",\n",
    "# #             \"pond\": \"0x57b946008913b82e4df85f501cbaed910e58d26c\",\n",
    "#             \"elf\":\"0xbf2179859fc6d5bee9bf9158632dc51678a4100e\", \n",
    "#             \"skl\":\"0x00c83aecc790e8a4453e5dd3b0b4b3680501a7a7\",\n",
    "#             \"rep\":\"0x221657776846890989a759ba2973e427dff5c9bb\"\n",
    "#                \"hot\":\"0x6c6ee5e31d828de241282b9606c8e98ea48526e2\",\n",
    "#                 \"mtl\":\"0xF433089366899D83a9f26A773D59ec7eCF30355e\",\n",
    "#                 \"inj\":\"0xe28b3b32b6c345a34ff64674606124dd5aceca30\",\n",
    "#                 \"mana\":\"0x0f5d2fb29fb7d3cfee444a200298f468908cc942\",\n",
    "#                 \"qnt\":\"0x4a220e6096b25eadb88358cb44068a3248254675\",\n",
    "#                 \"dnt\":\"0x0abdace70d3790235af448c88547603b945604ea\"\n",
    "                \"snx\":'0xc011a73ee8576fb46f5e1c5751ca3b9fe0af2a6f',\n",
    "            }\n",
    "url = 'https://api.bloxy.info/token/token_holders_list'\n",
    "\n",
    "responses = {}\n",
    "for token, tkn_add in addresses.items():\n",
    "    parameters = {\n",
    "      'token':tkn_add,\n",
    "      'key':api_key,\n",
    "      'limit': 2000\n",
    "    }\n",
    "    headers = {\n",
    "      'Accepts': 'application/json',\n",
    "    }\n",
    "\n",
    "\n",
    "    session = Session()\n",
    "    session.headers.update(headers)\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, params=parameters)\n",
    "        data = json.loads(response.text)\n",
    "        responses[token] = data\n",
    "    except (ConnectionError, Timeout, TooManyRedirects) as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import date\n",
    "file_name = 'bloxy/{}_1.json'.format(str(date.today()))\n",
    "\n",
    "my_file = Path(file_name)\n",
    "i = 2\n",
    "while my_file.is_file():\n",
    "    file_name = file_name.replace('.json','')[:-1] + str(i) + '.json'\n",
    "    my_file = Path(file_name)\n",
    "    i +=1\n",
    "with open(my_file, 'w') as f:\n",
    "    f.write(json.dumps(responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_id_map = {\n",
    "\"eth\":1,\n",
    "\"matic\":137,\n",
    "\"avalanche\":43114,\n",
    "\"binance\":56}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "74it [03:15,  2.65s/it]"
     ]
    }
   ],
   "source": [
    "holders = []\n",
    "parameters = {\n",
    "  'key':api_key\n",
    "}\n",
    "headers = {\n",
    "  'Accepts': 'application/json',\n",
    "}\n",
    "session = Session()\n",
    "session.headers.update(headers)\n",
    "\n",
    "from tqdm import tqdm\n",
    "for token, token_holders in responses.items():\n",
    "    for holder_idx, holder_details in tqdm(enumerate(token_holders)):\n",
    "        if holder_idx>=57:\n",
    "            if holder_details['address_type'].lower() == 'wallet' and holder_details['annotation'] == '':\n",
    "                holder_address = holder_details['address'] \n",
    "\n",
    "                try:\n",
    "                    url = \"https://api.covalenthq.com/v1/1/address/{}/portfolio_v2/\".format(holder_address)\n",
    "                    response = session.get(url, params=parameters)\n",
    "                    data = json.loads(response.text)\n",
    "                    holders.append({'token':token, 'holder_address': holder_address, 'data': data})\n",
    "                except (ConnectionError, Timeout, TooManyRedirects, JSONDecodeError) as e:\n",
    "                    print(e,token )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "file_name = 'covalent/token_holders.json'\n",
    "\n",
    "my_file = Path(file_name)\n",
    "i = 2\n",
    "while my_file.is_file():\n",
    "    file_name = file_name.replace('.json','')[:-1] + str(i) + '.json'\n",
    "    my_file = Path(file_name)\n",
    "    i +=1\n",
    "with open(my_file, 'w') as f:\n",
    "    f.write(json.dumps(holders))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "import math\n",
    "data_list = []\n",
    "zero_rate = 0\n",
    "for holder in holders:\n",
    "    data = holder['data']\n",
    "    root_token = holder['token']\n",
    "    items = data['items']\n",
    "    record_time = parse(data['updated_at']).date()\n",
    "    holder_address = holder['holder_address']\n",
    "    for contract in items: \n",
    "        \n",
    "        token_name = contract['contract_name']\n",
    "        token_symbol = contract['contract_ticker_symbol'].lower()\n",
    "        if token_symbol == 'matic':\n",
    "            continue\n",
    "        holdings = contract['holdings']\n",
    "        oldest_record = holdings[-1]\n",
    "        newest_record = holdings[0]\n",
    "        decimals = contract['contract_decimals']\n",
    "        or_balance = int(oldest_record['close']['balance'])\n",
    "        or_balance = math.pow(10, -decimals) * or_balance\n",
    "        nw_balance = int(newest_record['close']['balance'])\n",
    "        nw_balance = math.pow(10, -decimals) * nw_balance\n",
    "        or_quote = float(oldest_record['close']['quote']) if oldest_record['close']['quote'] else 0\n",
    "        nw_quote = float(newest_record['close']['quote']) if newest_record['close']['quote'] else 0\n",
    "        or_rate = float(oldest_record['quote_rate'])  if oldest_record['quote_rate'] else 0\n",
    "        nw_rate = float(newest_record['quote_rate']) if newest_record['quote_rate'] else 0\n",
    "        or_date = parse(oldest_record['timestamp']).date()\n",
    "        nw_date = parse(newest_record['timestamp']).date()\n",
    "        \n",
    "        if nw_rate ==0 and or_rate ==0:\n",
    "            rate_change =0 \n",
    "        else:\n",
    "            rate_change = round(100 * (nw_rate - or_rate)/ (or_rate + 0.00000000000000000000000000000000000000000001), 1)\n",
    "        \n",
    "        rank = -1\n",
    "        alive = 'NA'\n",
    "        type_ = \"NA\"\n",
    "        is_active = \"NA\"\n",
    "        is_new = \"NA\"\n",
    "        try:\n",
    "            rank_data = idx_coin_data[token_symbol]\n",
    "            \n",
    "            rank = rank_data['rank']\n",
    "            is_new = rank_data['is_new']\n",
    "            type_ = rank_data['type']\n",
    "            is_active = rank_data['is_active']\n",
    "            \n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        ## cowboy coding but whatever\n",
    "        positive_holdings = 0\n",
    "        for contract in items:\n",
    "            if int(contract['holdings'][0]['close']['balance'])>0:\n",
    "                positive_holdings += 1\n",
    "            \n",
    "        output = { \n",
    "                    \"holder_address\": holder_address,\n",
    "                    \"root_token\": root_token,\n",
    "                    \"record_time\": record_time,\n",
    "                    \"token_name\": token_name,\n",
    "                    \"token_symbol\": token_symbol,\n",
    "                    \"or_balance\": or_balance,\n",
    "                    \"nw_balance\": nw_balance,\n",
    "                    \"or_quote\": or_quote,\n",
    "                    \"nw_quote\": nw_quote,\n",
    "                    \"or_rate\": or_rate,\n",
    "                    \"nw_rate\": nw_rate,\n",
    "                    \"or_date\": or_date,\n",
    "                    \"nw_date\": nw_date,\n",
    "                    \"rate_change\": rate_change,\n",
    "                    \"num_holdings\": positive_holdings, \n",
    "                    \"rank\": rank, \n",
    "                    'is_new': is_new,\n",
    "                    'type_': type_,\n",
    "                    'is_active': is_active,\n",
    "                    'is_root': root_token == token_symbol\n",
    "            \n",
    "        }\n",
    "        data_list.append(output)\n",
    "        \n",
    "holders_df = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('pre_filtering', holders_df.shape)\n",
    "filtered_df = holders_df.query('num_holdings  > 4 & num_holdings < 40 & is_root == False & is_active == True and rate_change > 50')\n",
    "print('post_filtering', filtered_df.shape)\n",
    "len(filtered_df.holder_address.unique())\n",
    "watch_df = holders_df.query('or_quote  > 0 & is_root == False & nw_quote>10000')\n",
    "watch_df = watch_df[watch_df['holder_address'].isin(filtered_df.holder_address.unique())]\n",
    "multiple_wins = watch_df[watch_df['rate_change']>50].groupby('holder_address').count().sort_values(by=['rate_change'], ascending=False)\n",
    "multiple_wins = multiple_wins[multiple_wins['rate_change'] > 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_wins_addresses = watch_df[watch_df['holder_address'].isin(multiple_wins.index)].groupby('holder_address').count()\n",
    "pd.merge(multiple_wins_addresses['rate_change'], multiple_wins['rate_change'], on=multiple_wins.index)\n",
    "# .to_csv(\"/home/hq16960/blg_projects/covid19/stock_cluster/matic_holders_v1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_py36",
   "language": "python",
   "name": "conda_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
